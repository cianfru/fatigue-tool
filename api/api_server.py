"""
api_server.py - FastAPI Backend for Fatigue Analysis Tool
==========================================================

RESTful API exposing your Python fatigue model to frontend.

Endpoints:
- POST /api/analyze - Upload roster, get analysis
- GET /api/analysis/{id} - Get stored analysis
- POST /api/visualize/chronogram - Generate chronogram image
- POST /api/visualize/calendar - Generate aviation calendar

Usage:
    uvicorn api_server:app --reload --host 0.0.0.0 --port 8000
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
from typing import Optional, List
import tempfile
import os
from datetime import datetime
import base64
from pathlib import Path

# Import your fatigue model
from core import BorbelyFatigueModel, ModelConfig
from parsers.roster_parser import PDFRosterParser, CSVRosterParser, AirportDatabase
from models.data_models import MonthlyAnalysis, DutyTimeline
from visualization.chronogram import FatigueChronogram
from visualization.aviation_calendar import AviationCalendar

# ============================================================================
# FASTAPI APP INITIALIZATION
# ============================================================================

app = FastAPI(
    title="Fatigue Analysis API",
    description="EASA-compliant biomathematical fatigue analysis with sleep quality modeling",
    version="4.2.0"
)

# CORS - Allow Lovable frontend to connect
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5173",
        "http://localhost:8080",
        "https://*.lovable.app",
        "https://*.lovable.dev",
        "https://fatigue-insight-hub.lovable.app",
        "*"  # For development - restrict in production!
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# REQUEST/RESPONSE MODELS
# ============================================================================

class AnalysisRequest(BaseModel):
    pilot_id: str
    month: str  # Format: "2026-02"
    home_base: str  # Airport code (e.g., "DOH")
    home_timezone: str  # e.g., "Asia/Qatar"
    config_preset: str = "default"  # "default", "conservative", "liberal", "research"


class AirportResponse(BaseModel):
    """Airport information from the backend's ~7,800 airport database"""
    code: str           # IATA code (e.g., "LHR")
    timezone: str       # IANA timezone (e.g., "Europe/London")
    utc_offset_hours: Optional[float] = None  # Current UTC offset (accounts for DST)
    latitude: float = 0.0
    longitude: float = 0.0


class DutySegmentResponse(BaseModel):
    flight_number: str
    departure: str
    arrival: str
    departure_time: str  # UTC ISO format
    arrival_time: str    # UTC ISO format
    # Home base timezone times (HH:mm) - same reference TZ for all segments
    departure_time_local: str  # Home base local time in HH:mm format (kept for backward compat)
    arrival_time_local: str    # Home base local time in HH:mm format (kept for backward compat)
    # Explicit home-base timezone times (identical to _local, but unambiguous naming)
    departure_time_home_tz: str = ""  # HH:mm in home base timezone
    arrival_time_home_tz: str = ""    # HH:mm in home base timezone
    # Airport-local times (in the actual departure/arrival airport timezone)
    departure_time_airport_local: str = ""  # HH:mm in departure airport local TZ
    arrival_time_airport_local: str = ""    # HH:mm in arrival airport local TZ
    # Timezone metadata for each airport
    departure_timezone: str = ""  # IANA timezone of departure airport
    arrival_timezone: str = ""    # IANA timezone of arrival airport
    departure_utc_offset: Optional[float] = None  # UTC offset at departure (hours, e.g. +3.0)
    arrival_utc_offset: Optional[float] = None     # UTC offset at arrival (hours, e.g. +5.5)
    block_hours: float


class QualityFactorsResponse(BaseModel):
    """Breakdown of multiplicative quality factors applied to raw sleep duration.
    Each factor is a multiplier around 1.0 (>1 = boost, <1 = penalty).
    effective_sleep = duration * product(all factors), clamped to [0.65, 1.0]."""
    base_efficiency: float        # Location-based: home 0.90, hotel 0.85, crew_rest 0.70
    wocl_boost: float             # WOCL-aligned sleep consolidation boost (1.0-1.15)
    late_onset_penalty: float     # Penalty for sleep starting after 01:00 (0.93-1.0)
    recovery_boost: float         # Post-duty homeostatic drive boost (1.0-1.10)
    time_pressure_factor: float   # Proximity to next duty (0.88-1.03)
    insufficient_penalty: float   # Penalty for <6h sleep (0.75-1.0)


class SleepBlockResponse(BaseModel):
    """Individual sleep period with timing and optional quality breakdown"""
    sleep_start_time: str  # HH:mm in home-base timezone
    sleep_end_time: str    # HH:mm in home-base timezone
    sleep_start_iso: str   # ISO format with date for proper chronogram positioning
    sleep_end_iso: str     # ISO format with date for proper chronogram positioning
    sleep_type: str        # 'main', 'nap', 'anchor'
    duration_hours: float
    effective_hours: float
    quality_factor: float

    # Location context — needed for local-time labels on chronogram
    location_timezone: Optional[str] = None    # IANA tz where pilot physically sleeps
    environment: Optional[str] = None          # 'home', 'hotel', 'crew_rest'
    sleep_start_time_location_tz: Optional[str] = None  # HH:mm in location timezone
    sleep_end_time_location_tz: Optional[str] = None    # HH:mm in location timezone

    # Numeric grid positioning (home-base TZ)
    sleep_start_day: Optional[int] = None      # Day of month (1-31)
    sleep_start_hour: Optional[float] = None   # Decimal hour (0-24)
    sleep_end_day: Optional[int] = None
    sleep_end_hour: Optional[float] = None

    # Explicit home-base timezone positioning (preferred by frontend)
    sleep_start_day_home_tz: Optional[int] = None
    sleep_start_hour_home_tz: Optional[float] = None
    sleep_end_day_home_tz: Optional[int] = None
    sleep_end_hour_home_tz: Optional[float] = None
    sleep_start_time_home_tz: Optional[str] = None    # HH:mm
    sleep_end_time_home_tz: Optional[str] = None      # HH:mm

    # Per-block quality factor breakdown (populated for all sleep types)
    quality_factors: Optional[QualityFactorsResponse] = None


class ReferenceResponse(BaseModel):
    """Peer-reviewed scientific reference supporting the calculation"""
    key: str     # e.g. 'roach_2012'
    short: str   # e.g. 'Roach et al. (2012)'
    full: str    # Full citation


class SleepQualityResponse(BaseModel):
    """Sleep quality analysis with scientific methodology transparency"""
    total_sleep_hours: float
    effective_sleep_hours: float
    sleep_efficiency: float
    wocl_overlap_hours: float
    sleep_strategy: str  # 'anchor', 'split', 'nap', 'early_bedtime', 'afternoon_nap', 'extended', 'restricted', 'normal', 'recovery', 'post_duty_recovery'
    confidence: float
    warnings: List[str]
    sleep_blocks: List[SleepBlockResponse] = []  # All sleep periods
    sleep_start_time: Optional[str] = None  # Primary sleep start (HH:mm)
    sleep_end_time: Optional[str] = None    # Primary sleep end (HH:mm)
    sleep_start_iso: Optional[str] = None   # Primary sleep start (ISO format with date for chronogram)
    sleep_end_iso: Optional[str] = None     # Primary sleep end (ISO format with date for chronogram)

    # Numeric grid positioning from primary sleep block (home-base TZ)
    sleep_start_day: Optional[int] = None       # Day of month (1-31)
    sleep_start_hour: Optional[float] = None    # Decimal hour (0-24)
    sleep_end_day: Optional[int] = None
    sleep_end_hour: Optional[float] = None

    # Explicit home-base timezone positioning (preferred by frontend)
    sleep_start_day_home_tz: Optional[int] = None
    sleep_start_hour_home_tz: Optional[float] = None
    sleep_end_day_home_tz: Optional[int] = None
    sleep_end_hour_home_tz: Optional[float] = None
    sleep_start_time_home_tz: Optional[str] = None    # HH:mm
    sleep_end_time_home_tz: Optional[str] = None      # HH:mm

    # Scientific methodology (new — surfaces calculation transparency)
    explanation: Optional[str] = None              # Human-readable strategy description
    confidence_basis: Optional[str] = None         # Why confidence is at this level
    quality_factors: Optional[QualityFactorsResponse] = None  # Factor breakdown
    references: List[ReferenceResponse] = []       # Supporting literature


class DutyResponse(BaseModel):
    duty_id: str
    date: str
    report_time_utc: str
    release_time_utc: str
    # Local time strings for direct display (HH:MM in home timezone)
    report_time_local: Optional[str] = None    # Kept for backward compat
    release_time_local: Optional[str] = None   # Kept for backward compat
    # Explicit home-base timezone times (identical to _local, unambiguous naming)
    report_time_home_tz: Optional[str] = None  # HH:MM in home base timezone
    release_time_home_tz: Optional[str] = None # HH:MM in home base timezone
    duty_hours: float
    sectors: int
    segments: List[DutySegmentResponse]
    
    # Performance metrics
    min_performance: float
    avg_performance: float
    landing_performance: Optional[float]
    
    # Fatigue metrics
    sleep_debt: float
    wocl_hours: float
    prior_sleep: float
    pre_duty_awake_hours: float = 0.0  # hours awake before report
    
    # Risk
    risk_level: str  # "low", "moderate", "high", "critical", "extreme"
    is_reportable: bool
    pinch_events: int
    
    # EASA FDP limits
    max_fdp_hours: Optional[float]  # Base FDP limit
    extended_fdp_hours: Optional[float]  # With captain discretion
    used_discretion: bool  # True if exceeded base limit
    
    # Circadian adaptation state at duty report time
    circadian_phase_shift: Optional[float] = None  # Hours offset from home base body clock

    # Enhanced sleep quality analysis
    sleep_quality: Optional[SleepQualityResponse] = None

    # Validation warnings (NEW - BUG FIX #5)
    time_validation_warnings: List[str] = []

    # Augmented crew / ULR data
    crew_composition: str = "standard"
    rest_facility_class: Optional[str] = None
    is_ulr: bool = False
    acclimatization_state: str = "acclimatized"
    ulr_compliance: Optional[dict] = None
    inflight_rest_blocks: List[dict] = []
    return_to_deck_performance: Optional[float] = None


class RestDaySleepResponse(BaseModel):
    """Sleep pattern for a rest day (no duties) with full scientific methodology"""
    date: str  # YYYY-MM-DD
    sleep_blocks: List[SleepBlockResponse]
    total_sleep_hours: float
    effective_sleep_hours: float
    sleep_efficiency: float
    strategy_type: str  # 'recovery', 'post_duty_recovery', or other strategy types
    confidence: float

    # Scientific methodology — consistent with SleepQualityResponse
    explanation: Optional[str] = None
    confidence_basis: Optional[str] = None
    quality_factors: Optional[QualityFactorsResponse] = None
    references: List[ReferenceResponse] = []

    # Recovery context (for recovery strategy_type)
    recovery_night_number: Optional[int] = None           # Which recovery night (1-indexed)
    cumulative_recovery_fraction: Optional[float] = None  # 0-1 fraction of debt recovered


class AnalysisResponse(BaseModel):
    analysis_id: str
    roster_id: str
    pilot_id: str
    pilot_name: Optional[str]  # Extracted from PDF
    pilot_base: Optional[str]  # Home base airport
    pilot_aircraft: Optional[str]  # Aircraft type
    home_base_timezone: Optional[str] = None  # IANA timezone (e.g., "Asia/Qatar")
    timezone_format: Optional[str] = None  # 'auto', 'local', 'homebase', 'zulu' — how roster times were interpreted
    month: str
    
    # Summary
    total_duties: int
    total_sectors: int
    total_duty_hours: float
    total_block_hours: float
    
    # Risk summary
    high_risk_duties: int
    critical_risk_duties: int
    total_pinch_events: int
    
    # Sleep metrics
    avg_sleep_per_night: float
    max_sleep_debt: float
    
    # Worst case
    worst_duty_id: str
    worst_performance: float
    
    # Detailed duties
    duties: List[DutyResponse]
    
    # Rest days sleep patterns
    rest_days_sleep: List[RestDaySleepResponse] = []

    # Circadian adaptation curve for body-clock chronogram
    # List of {timestamp_utc, phase_shift_hours, reference_timezone}
    body_clock_timeline: List[dict] = []

    # Augmented crew / ULR summary
    total_ulr_duties: int = 0
    total_augmented_duties: int = 0
    ulr_violations: List[str] = []


class ChronogramRequest(BaseModel):
    analysis_id: str
    mode: str = "risk"  # "risk", "state", "hybrid"
    theme: str = "light"
    show_annotations: bool = True


class CalendarRequest(BaseModel):
    analysis_id: str
    theme: str = "light"


# ============================================================================
# IN-MEMORY STORAGE (Replace with database in production)
# ============================================================================

analysis_store = {}  # analysis_id -> (MonthlyAnalysis, Roster)


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def classify_risk(performance: Optional[float]) -> str:
    """Classify risk level based on performance score"""
    if performance is None:
        return "unknown"
    if performance >= 75:
        return "low"
    elif performance >= 65:
        return "moderate"
    elif performance >= 55:
        return "high"
    elif performance >= 45:
        return "critical"
    else:
        return "extreme"


def _build_duty_response(duty_timeline, duty, roster) -> DutyResponse:
    """Shared serialization for a single duty — used by both POST and GET endpoints."""
    import pytz

    risk = classify_risk(duty_timeline.landing_performance)
    home_tz = pytz.timezone(duty.home_base_timezone)

    # Build segments
    segments = []
    for seg in duty.segments:
        dep_utc = seg.scheduled_departure_utc
        arr_utc = seg.scheduled_arrival_utc

        # Convert to HOME BASE timezone for chronogram positioning
        # All times in the same reference TZ keeps duty bars proportional.
        dep_home = dep_utc.astimezone(home_tz)
        arr_home = arr_utc.astimezone(home_tz)

        # Also convert to actual airport-local timezone for display
        dep_airport_tz = pytz.timezone(seg.departure_airport.timezone)
        arr_airport_tz = pytz.timezone(seg.arrival_airport.timezone)
        dep_airport_local = dep_utc.astimezone(dep_airport_tz)
        arr_airport_local = arr_utc.astimezone(arr_airport_tz)

        # Calculate UTC offsets at the time of departure/arrival (DST-aware)
        dep_utc_offset = dep_airport_local.utcoffset().total_seconds() / 3600
        arr_utc_offset = arr_airport_local.utcoffset().total_seconds() / 3600

        segments.append(DutySegmentResponse(
            flight_number=seg.flight_number,
            departure=seg.departure_airport.code,
            arrival=seg.arrival_airport.code,
            departure_time=dep_utc.isoformat(),
            arrival_time=arr_utc.isoformat(),
            # Backward-compatible fields (home base TZ)
            departure_time_local=dep_home.strftime("%H:%M"),
            arrival_time_local=arr_home.strftime("%H:%M"),
            # Explicit home-base TZ fields
            departure_time_home_tz=dep_home.strftime("%H:%M"),
            arrival_time_home_tz=arr_home.strftime("%H:%M"),
            # Actual airport-local times
            departure_time_airport_local=dep_airport_local.strftime("%H:%M"),
            arrival_time_airport_local=arr_airport_local.strftime("%H:%M"),
            # Timezone metadata
            departure_timezone=seg.departure_airport.timezone,
            arrival_timezone=seg.arrival_airport.timezone,
            departure_utc_offset=dep_utc_offset,
            arrival_utc_offset=arr_utc_offset,
            block_hours=seg.block_time_hours
        ))

    # Convert report/release to home timezone for display
    report_local = duty.report_time_utc.astimezone(home_tz)
    release_local = duty.release_time_utc.astimezone(home_tz)

    # Time validation warnings
    time_warnings = []
    if duty.report_time_utc >= duty.release_time_utc:
        time_warnings.append("Invalid duty: report time >= release time")
    if duty.duty_hours > 24 and not getattr(duty, 'is_ulr', False):
        time_warnings.append(f"Unusual duty length: {duty.duty_hours:.1f} hours")
    elif duty.duty_hours > 23 and getattr(duty, 'is_ulr', False):
        time_warnings.append(f"ULR duty exceeds max discretion limit: {duty.duty_hours:.1f} hours")
    if duty.duty_hours < 0.5:
        time_warnings.append(f"Very short duty: {duty.duty_hours:.1f} hours")

    # Sleep quality (with scientific methodology)
    sleep_quality = None
    if duty_timeline.sleep_quality_data:
        sqd = duty_timeline.sleep_quality_data
        first_block = sqd.get('sleep_blocks', [{}])[0] if sqd.get('sleep_blocks') else {}
        sleep_quality = SleepQualityResponse(
            total_sleep_hours=sqd.get('total_sleep_hours', 0.0),
            effective_sleep_hours=sqd.get('effective_sleep_hours', 0.0),
            sleep_efficiency=sqd.get('sleep_efficiency', 0.0),
            wocl_overlap_hours=sqd.get('wocl_overlap_hours', 0.0),
            sleep_strategy=sqd.get('strategy_type', 'unknown'),
            confidence=sqd.get('confidence', 0.0),
            warnings=sqd.get('warnings', []),
            sleep_blocks=sqd.get('sleep_blocks', []),
            sleep_start_time=sqd.get('sleep_start_time'),
            sleep_end_time=sqd.get('sleep_end_time'),
            # Scientific methodology
            explanation=sqd.get('explanation'),
            confidence_basis=sqd.get('confidence_basis'),
            quality_factors=sqd.get('quality_factors'),
            references=sqd.get('references', []),
            # Chronogram positioning from first sleep block
            sleep_start_iso=first_block.get('sleep_start_iso'),
            sleep_end_iso=first_block.get('sleep_end_iso'),
            sleep_start_day=first_block.get('sleep_start_day'),
            sleep_start_hour=first_block.get('sleep_start_hour'),
            sleep_end_day=first_block.get('sleep_end_day'),
            sleep_end_hour=first_block.get('sleep_end_hour'),
            # Home-base TZ positioning (preferred by frontend)
            sleep_start_day_home_tz=first_block.get('sleep_start_day_home_tz'),
            sleep_start_hour_home_tz=first_block.get('sleep_start_hour_home_tz'),
            sleep_end_day_home_tz=first_block.get('sleep_end_day_home_tz'),
            sleep_end_hour_home_tz=first_block.get('sleep_end_hour_home_tz'),
            sleep_start_time_home_tz=first_block.get('sleep_start_time_home_tz'),
            sleep_end_time_home_tz=first_block.get('sleep_end_time_home_tz'),
        )

    # Augmented crew / ULR data
    ulr_compliance_dict = None
    if getattr(duty_timeline, 'ulr_compliance', None):
        uc = duty_timeline.ulr_compliance
        ulr_compliance_dict = {
            'is_ulr': uc.is_ulr,
            'pre_rest_compliant': uc.pre_ulr_rest_compliant,
            'post_rest_compliant': uc.post_ulr_rest_compliant,
            'monthly_count': uc.monthly_ulr_count,
            'monthly_compliant': uc.monthly_ulr_compliant,
            'fdp_within_limit': uc.fdp_within_limit,
            'rest_periods_valid': uc.rest_periods_valid,
            'violations': uc.violations,
            'warnings': uc.warnings,
        }

    inflight_blocks = []
    rest_periods = []
    if hasattr(duty, 'inflight_rest_plan') and duty.inflight_rest_plan:
        rest_periods = duty.inflight_rest_plan.rest_periods
    for i, block in enumerate(getattr(duty_timeline, 'inflight_rest_blocks', [])):
        period = rest_periods[i] if i < len(rest_periods) else None
        inflight_blocks.append({
            'start_utc': block.start_utc.isoformat() if block.start_utc else None,
            'end_utc': block.end_utc.isoformat() if block.end_utc else None,
            'duration_hours': block.duration_hours,
            'effective_sleep_hours': block.effective_sleep_hours,
            'quality_factor': block.quality_factor,
            'environment': block.environment,
            'crew_member_id': period.crew_member_id if period else None,
            'crew_set': period.crew_set if period else None,
            'is_during_wocl': period.is_during_wocl if period else False,
        })

    return DutyResponse(
        duty_id=duty_timeline.duty_id,
        date=duty_timeline.duty_date.strftime("%Y-%m-%d"),
        report_time_utc=duty.report_time_utc.isoformat(),
        release_time_utc=duty.release_time_utc.isoformat(),
        report_time_local=report_local.strftime("%H:%M"),
        release_time_local=release_local.strftime("%H:%M"),
        report_time_home_tz=report_local.strftime("%H:%M"),
        release_time_home_tz=release_local.strftime("%H:%M"),
        duty_hours=duty.duty_hours,
        sectors=len(duty.segments),
        segments=segments,
        min_performance=duty_timeline.min_performance,
        avg_performance=duty_timeline.average_performance,
        landing_performance=duty_timeline.landing_performance,
        sleep_debt=duty_timeline.cumulative_sleep_debt,
        wocl_hours=duty_timeline.wocl_encroachment_hours,
        prior_sleep=duty_timeline.prior_sleep_hours,
        pre_duty_awake_hours=duty_timeline.pre_duty_awake_hours,
        risk_level=risk,
        is_reportable=(risk in ["critical", "extreme"]),
        pinch_events=len(duty_timeline.pinch_events),
        max_fdp_hours=duty.max_fdp_hours,
        extended_fdp_hours=duty.extended_fdp_hours,
        used_discretion=duty.used_discretion,
        circadian_phase_shift=round(duty_timeline.circadian_phase_shift, 2),
        time_validation_warnings=time_warnings,
        sleep_quality=sleep_quality,
        # Augmented crew / ULR
        crew_composition=duty.crew_composition.value if hasattr(duty.crew_composition, 'value') else str(getattr(duty, 'crew_composition', 'standard')),
        rest_facility_class=duty.rest_facility_class.value if getattr(duty, 'rest_facility_class', None) else None,
        is_ulr=getattr(duty_timeline, 'is_ulr', False),
        acclimatization_state=duty_timeline.acclimatization_state.value if hasattr(getattr(duty_timeline, 'acclimatization_state', None), 'value') else str(getattr(duty_timeline, 'acclimatization_state', 'acclimatized')),
        ulr_compliance=ulr_compliance_dict,
        inflight_rest_blocks=inflight_blocks,
        return_to_deck_performance=getattr(duty_timeline, 'return_to_deck_performance', None),
    )


def _build_rest_days_sleep(sleep_strategies: dict) -> List[RestDaySleepResponse]:
    """
    Extract rest-day sleep AND post-duty layover sleep from sleep_strategies dict.

    Post-duty sleep (e.g., hotel rest after landing at 2AM) is included here
    so the frontend can display it in the chronogram even though it's technically
    not a "rest day" - it's recovery sleep after a duty.
    """
    rest_days = []

    # Include both rest day sleep (rest_*) and post-duty sleep (post_duty_*)
    for key, data in sleep_strategies.items():
        if key.startswith('rest_') or key.startswith('post_duty_'):
            # Extract date from key (rest_2024-01-15 or post_duty_D001)
            if key.startswith('rest_'):
                date_str = key.replace('rest_', '')
            else:
                # For post-duty, use the date from the first sleep block if available
                blocks = data.get('sleep_blocks', [])
                if blocks and 'sleep_start_iso' in blocks[0]:
                    # Extract date from ISO timestamp (YYYY-MM-DDTHH:mm...)
                    date_str = blocks[0]['sleep_start_iso'].split('T')[0]
                else:
                    continue  # Skip if no date info available

            rest_days.append(RestDaySleepResponse(
                date=date_str,
                sleep_blocks=data.get('sleep_blocks', []),
                total_sleep_hours=data.get('total_sleep_hours', 0.0),
                effective_sleep_hours=data.get('effective_sleep_hours', 0.0),
                sleep_efficiency=data.get('sleep_efficiency', 0.0),
                strategy_type=data.get('strategy_type', 'recovery'),
                confidence=data.get('confidence', 0.0),
                # Scientific methodology — now always populated
                explanation=data.get('explanation'),
                confidence_basis=data.get('confidence_basis'),
                quality_factors=data.get('quality_factors'),
                references=data.get('references', []),
                # Recovery context
                recovery_night_number=data.get('recovery_night_number'),
                cumulative_recovery_fraction=data.get('cumulative_recovery_fraction'),
            ))
    return rest_days


# ============================================================================
# ENDPOINTS
# ============================================================================

@app.get("/")
async def root():
    """Health check"""
    return {
        "status": "ok",
        "service": "Fatigue Analysis API",
        "version": "4.2.0",
        "model": "Borbély Two-Process + Workload Integration"
    }


@app.get("/debug/timezone-test")
async def timezone_test():
    """Debug endpoint to test timezone conversions"""
    import pytz
    from datetime import datetime

    # Test case from screenshot: CCJ → DOH
    dep_utc_str = "2026-02-01T22:25:00Z"
    arr_utc_str = "2026-02-01T02:55:00Z"

    dep_utc = datetime.fromisoformat(dep_utc_str.replace('Z', '+00:00'))
    arr_utc = datetime.fromisoformat(arr_utc_str.replace('Z', '+00:00'))

    # Convert to different timezones
    india_tz = pytz.timezone("Asia/Kolkata")
    qatar_tz = pytz.timezone("Asia/Qatar")

    return {
        "departure_utc": dep_utc_str,
        "arrival_utc": arr_utc_str,
        "conversions": {
            "departure_india": dep_utc.astimezone(india_tz).strftime("%H:%M"),
            "departure_qatar": dep_utc.astimezone(qatar_tz).strftime("%H:%M"),
            "arrival_india": arr_utc.astimezone(india_tz).strftime("%H:%M"),
            "arrival_qatar": arr_utc.astimezone(qatar_tz).strftime("%H:%M"),
        },
        "expected_for_home_base_chronogram": {
            "departure": "01:25 (Qatar time)",
            "arrival": "05:55 (Qatar time)"
        },
        "what_screenshot_shows": {
            "departure": "03:55 (India time - WRONG)",
            "arrival": "08:25 (India time - WRONG)"
        }
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_roster(
    file: UploadFile = File(...),
    pilot_id: str = Form("P12345"),
    month: str = Form("2026-02"),
    home_base: str = Form("DOH"),
    home_timezone: str = Form("Asia/Qatar"),
    config_preset: str = Form("default"),
    timezone_format: str = Form("auto"),
    crew_set: str = Form("crew_b"),
    duty_crew_overrides: str = Form("{}")
):
    """
    Upload roster file and get fatigue analysis
    
    Returns complete analysis with duty-by-duty breakdown
    """
    
    try:
        # Validate file
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        # Save uploaded file
        suffix = Path(file.filename).suffix.lower()
        if suffix not in ['.pdf', '.csv']:
            raise HTTPException(status_code=400, detail="Unsupported file format. Use PDF or CSV.")
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            content = await file.read()
            tmp.write(content)
            tmp_path = tmp.name
        
        try:
            # Validate timezone_format parameter
            valid_tz_formats = ('auto', 'local', 'homebase', 'zulu')
            if timezone_format.lower() not in valid_tz_formats:
                raise HTTPException(
                    status_code=400,
                    detail=f"Invalid timezone_format '{timezone_format}'. Must be one of: {', '.join(valid_tz_formats)}"
                )

            # Parse roster
            if suffix == '.pdf':
                parser = PDFRosterParser(
                    home_base=home_base,
                    home_timezone=home_timezone,
                    timezone_format=timezone_format.lower()
                )
                roster = parser.parse_pdf(tmp_path, pilot_id, month)
            else:  # CSV
                parser = CSVRosterParser(
                    home_base=home_base,
                    home_timezone=home_timezone
                )
                roster = parser.parse_csv(tmp_path, pilot_id, month)
        finally:
            # Clean up temp file
            os.unlink(tmp_path)
        
        # Validate roster
        if not roster.duties:
            raise HTTPException(status_code=400, detail="No duties found in roster")

        # Set crew set for ULR duties (Crew A or Crew B) with per-duty override support
        import json
        from models.data_models import ULRCrewSet

        # Parse per-duty crew overrides
        overrides_dict = {}
        try:
            overrides_dict = json.loads(duty_crew_overrides) if duty_crew_overrides else {}
        except (json.JSONDecodeError, TypeError):
            logger.warning("Invalid duty_crew_overrides JSON, using global setting")

        # Apply crew set to each duty (with per-duty override support)
        valid_crew_sets = {'crew_a': ULRCrewSet.CREW_A, 'crew_b': ULRCrewSet.CREW_B}

        for d in roster.duties:
            if hasattr(d, 'ulr_crew_set'):
                # Priority: duty-specific override > global setting
                crew_set_key = overrides_dict.get(d.duty_id, crew_set.lower())
                d.ulr_crew_set = valid_crew_sets.get(crew_set_key, ULRCrewSet.CREW_B)
        
        # Get config
        config_map = {
            "default": ModelConfig.default_easa_config,
            "conservative": ModelConfig.conservative_config,
            "liberal": ModelConfig.liberal_config,
            "research": ModelConfig.research_config
        }
        config_func = config_map.get(config_preset, ModelConfig.default_easa_config)
        config = config_func()
        
        # Run analysis
        model = BorbelyFatigueModel(config)
        monthly_analysis = model.simulate_roster(roster)
        
        # Generate analysis ID
        analysis_id = f"{pilot_id}_{month}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        # Store for later retrieval (include sleep_strategies for GET endpoint)
        analysis_store[analysis_id] = (monthly_analysis, roster, model.sleep_strategies)
        
        # Build response using shared helper
        duties_response = []
        for duty_timeline in monthly_analysis.duty_timelines:
            duty_idx = roster.get_duty_index(duty_timeline.duty_id)
            if duty_idx is None:
                continue
            duties_response.append(
                _build_duty_response(duty_timeline, roster.duties[duty_idx], roster)
            )

        rest_days_sleep = _build_rest_days_sleep(model.sleep_strategies)
        
        # Get effective timezone format (what the parser actually used)
        effective_tz_format = getattr(parser, 'effective_timezone_format', timezone_format)

        return AnalysisResponse(
            analysis_id=analysis_id,
            roster_id=roster.roster_id,
            pilot_id=roster.pilot_id,
            pilot_name=roster.pilot_name,
            pilot_base=roster.pilot_base,
            pilot_aircraft=roster.pilot_aircraft,
            home_base_timezone=roster.home_base_timezone,
            timezone_format=effective_tz_format,
            month=roster.month,
            total_duties=roster.total_duties,
            total_sectors=roster.total_sectors,
            total_duty_hours=roster.total_duty_hours,
            total_block_hours=roster.total_block_hours,
            high_risk_duties=monthly_analysis.high_risk_duties,
            critical_risk_duties=monthly_analysis.critical_risk_duties,
            total_pinch_events=monthly_analysis.total_pinch_events,
            avg_sleep_per_night=monthly_analysis.average_sleep_per_night,
            max_sleep_debt=monthly_analysis.max_sleep_debt,
            worst_duty_id=monthly_analysis.lowest_performance_duty,
            worst_performance=monthly_analysis.lowest_performance_value,
            duties=duties_response,
            rest_days_sleep=rest_days_sleep,
            body_clock_timeline=[
                {'timestamp_utc': ts, 'phase_shift_hours': ps, 'reference_timezone': tz}
                for ts, ps, tz in monthly_analysis.body_clock_timeline
            ],
            total_ulr_duties=getattr(monthly_analysis, 'total_ulr_duties', 0),
            total_augmented_duties=getattr(monthly_analysis, 'total_augmented_duties', 0),
            ulr_violations=getattr(monthly_analysis, 'ulr_violations', []),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


@app.get("/api/analysis/{analysis_id}")
async def get_analysis(analysis_id: str):
    """Retrieve stored analysis by ID"""

    if analysis_id not in analysis_store:
        raise HTTPException(status_code=404, detail="Analysis not found")

    monthly_analysis, roster, sleep_strategies = analysis_store[analysis_id]

    # Build duties response using shared helper
    duties_response = []
    for duty_timeline in monthly_analysis.duty_timelines:
        duty_idx = roster.get_duty_index(duty_timeline.duty_id)
        if duty_idx is None:
            continue
        duties_response.append(
            _build_duty_response(duty_timeline, roster.duties[duty_idx], roster)
        )

    rest_days_sleep = _build_rest_days_sleep(sleep_strategies)

    return AnalysisResponse(
        analysis_id=analysis_id,
        roster_id=roster.roster_id,
        pilot_id=roster.pilot_id,
        pilot_name=roster.pilot_name,
        pilot_base=roster.pilot_base,
        pilot_aircraft=roster.pilot_aircraft,
        home_base_timezone=roster.home_base_timezone,
        month=roster.month,
        total_duties=roster.total_duties,
        total_sectors=roster.total_sectors,
        total_duty_hours=roster.total_duty_hours,
        total_block_hours=roster.total_block_hours,
        high_risk_duties=monthly_analysis.high_risk_duties,
        critical_risk_duties=monthly_analysis.critical_risk_duties,
        total_pinch_events=monthly_analysis.total_pinch_events,
        avg_sleep_per_night=monthly_analysis.average_sleep_per_night,
        max_sleep_debt=monthly_analysis.max_sleep_debt,
        worst_duty_id=monthly_analysis.lowest_performance_duty,
        worst_performance=monthly_analysis.lowest_performance_value,
        duties=duties_response,
        rest_days_sleep=rest_days_sleep,
        body_clock_timeline=[
            {'timestamp_utc': ts, 'phase_shift_hours': ps, 'reference_timezone': tz}
            for ts, ps, tz in monthly_analysis.body_clock_timeline
        ],
        total_ulr_duties=getattr(monthly_analysis, 'total_ulr_duties', 0),
        total_augmented_duties=getattr(monthly_analysis, 'total_augmented_duties', 0),
        ulr_violations=getattr(monthly_analysis, 'ulr_violations', []),
    )


@app.post("/api/visualize/chronogram")
async def generate_chronogram(request: ChronogramRequest):
    """
    Generate high-resolution chronogram image
    Returns base64-encoded PNG
    """

    if request.analysis_id not in analysis_store:
        raise HTTPException(status_code=404, detail="Analysis not found")

    monthly_analysis, roster, _sleep_strategies = analysis_store[request.analysis_id]

    try:
        chrono = FatigueChronogram(theme=request.theme)

        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
            chrono.plot_monthly_chronogram(
                monthly_analysis,
                save_path=tmp.name,
                mode=request.mode,
                show_annotations=request.show_annotations
            )

            # Read and encode as base64
            with open(tmp.name, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode()

            os.unlink(tmp.name)

        return {
            "image": f"data:image/png;base64,{image_data}",
            "format": "png"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chronogram generation failed: {str(e)}")


@app.post("/api/visualize/calendar")
async def generate_calendar(request: CalendarRequest):
    """Generate aviation calendar image"""

    if request.analysis_id not in analysis_store:
        raise HTTPException(status_code=404, detail="Analysis not found")

    monthly_analysis, roster, _sleep_strategies = analysis_store[request.analysis_id]

    try:
        cal = AviationCalendar(theme=request.theme)

        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
            cal.plot_monthly_roster(monthly_analysis, save_path=tmp.name)

            with open(tmp.name, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode()

            os.unlink(tmp.name)

        return {
            "image": f"data:image/png;base64,{image_data}",
            "format": "png"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Calendar generation failed: {str(e)}")


@app.get("/api/duty/{analysis_id}/{duty_id}")
async def get_duty_detail(analysis_id: str, duty_id: str):
    """
    Get detailed timeline data for a single duty
    Returns all performance points for interactive charting
    """
    
    if analysis_id not in analysis_store:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    monthly_analysis, roster, _sleep_strategies = analysis_store[analysis_id]

    # Find duty
    duty_timeline = None
    for dt in monthly_analysis.duty_timelines:
        if dt.duty_id == duty_id:
            duty_timeline = dt
            break
    
    if not duty_timeline:
        raise HTTPException(status_code=404, detail="Duty not found")
    
    # Build timeline data for frontend charting
    timeline_data = []
    
    for point in duty_timeline.timeline:
        timeline_data.append({
            "timestamp": point.timestamp_utc.isoformat(),
            "timestamp_local": point.timestamp_local.isoformat(),
            "performance": point.raw_performance,
            "sleep_pressure": point.homeostatic_component,
            "circadian": point.circadian_component,
            # Factor form: 1.0 = no effect, <1.0 = degradation.
            # The frontend displays (factor - 1.0) * 100 as a percentage.
            "sleep_inertia": 1.0 - point.sleep_inertia_component,
            "hours_on_duty": point.hours_on_duty,
            "time_on_task_penalty": 1.0 - point.time_on_task_penalty,
            "flight_phase": point.current_flight_phase.value if point.current_flight_phase else None,
            "is_critical": point.is_critical_phase,
            "is_in_rest": getattr(point, 'is_in_rest', False),
        })

    return {
        "duty_id": duty_id,
        "timeline": timeline_data,
        "summary": {
            "min_performance": duty_timeline.min_performance,
            "avg_performance": duty_timeline.average_performance,
            "landing_performance": duty_timeline.landing_performance,
            "wocl_hours": duty_timeline.wocl_encroachment_hours,
            "prior_sleep": duty_timeline.prior_sleep_hours,
            "pre_duty_awake_hours": duty_timeline.pre_duty_awake_hours,
            "sleep_debt": duty_timeline.cumulative_sleep_debt
        },
        "pinch_events": [
            {
                "timestamp": pe.timestamp_utc.isoformat(),
                "performance": pe.performance_value,
                "phase": pe.flight_phase.value if pe.flight_phase else None,
                "cause": pe.cause
            }
            for pe in duty_timeline.pinch_events
        ]
    }


@app.get("/api/statistics/{analysis_id}")
async def get_statistics(analysis_id: str):
    """Get summary statistics for frontend dashboard"""
    
    if analysis_id not in analysis_store:
        raise HTTPException(status_code=404, detail="Analysis not found")
    
    monthly_analysis, roster, _sleep_strategies = analysis_store[analysis_id]

    # Calculate additional statistics
    all_perfs = [dt.landing_performance for dt in monthly_analysis.duty_timelines 
                 if dt.landing_performance is not None]
    
    return {
        "analysis_id": analysis_id,
        "summary": {
            "total_duties": roster.total_duties,
            "total_sectors": roster.total_sectors,
            "total_duty_hours": roster.total_duty_hours,
            "total_block_hours": roster.total_block_hours,
        },
        "risk": {
            "high_risk_duties": monthly_analysis.high_risk_duties,
            "critical_risk_duties": monthly_analysis.critical_risk_duties,
            "total_pinch_events": monthly_analysis.total_pinch_events,
        },
        "performance": {
            "average_landing_performance": sum(all_perfs) / len(all_perfs) if all_perfs else None,
            "min_landing_performance": min(all_perfs) if all_perfs else None,
            "max_landing_performance": max(all_perfs) if all_perfs else None,
            "worst_duty_id": monthly_analysis.lowest_performance_duty,
            "worst_performance": monthly_analysis.lowest_performance_value,
        },
        "sleep": {
            "avg_sleep_per_night": monthly_analysis.average_sleep_per_night,
            "max_sleep_debt": monthly_analysis.max_sleep_debt,
        }
    }


# ============================================================================
# AIRPORT DATABASE ENDPOINTS
# ============================================================================

@app.get("/api/airports/{iata_code}", response_model=AirportResponse)
async def get_airport(iata_code: str):
    """
    Look up airport by IATA code from backend's ~7,800 airport database.

    Returns timezone (IANA), coordinates, and current UTC offset.
    This eliminates the need for the frontend to maintain its own airport database.
    """
    import pytz

    airport = AirportDatabase.get_airport(iata_code)

    # Calculate current UTC offset (DST-aware)
    try:
        tz = pytz.timezone(airport.timezone)
        now = datetime.now(pytz.utc)
        utc_offset = tz.utcoffset(now).total_seconds() / 3600
    except Exception:
        utc_offset = None

    return AirportResponse(
        code=airport.code,
        timezone=airport.timezone,
        utc_offset_hours=utc_offset,
        latitude=airport.latitude,
        longitude=airport.longitude,
    )


class BatchAirportRequest(BaseModel):
    codes: List[str]  # List of IATA codes


@app.post("/api/airports/batch", response_model=List[AirportResponse])
async def get_airports_batch(request: BatchAirportRequest):
    """
    Batch lookup for multiple airports.

    Accepts up to 50 IATA codes and returns timezone + coordinate data for each.
    Use this to populate the frontend's airport data for a whole roster in one call.
    """
    import pytz

    if len(request.codes) > 50:
        raise HTTPException(status_code=400, detail="Maximum 50 airports per batch request")

    now = datetime.now(pytz.utc)
    results = []

    for code in request.codes:
        airport = AirportDatabase.get_airport(code)
        try:
            tz = pytz.timezone(airport.timezone)
            utc_offset = tz.utcoffset(now).total_seconds() / 3600
        except Exception:
            utc_offset = None

        results.append(AirportResponse(
            code=airport.code,
            timezone=airport.timezone,
            utc_offset_hours=utc_offset,
            latitude=airport.latitude,
            longitude=airport.longitude,
        ))

    return results


@app.get("/api/airports/search")
async def search_airports(q: str = Query(..., min_length=2, max_length=10)):
    """
    Search airports by IATA code prefix.

    Returns matching airports from the ~7,800 airport database.
    Useful for autocomplete in the frontend.
    """
    import airportsdata

    _db = airportsdata.load('IATA')
    q_upper = q.upper()
    matches = []

    for code, entry in _db.items():
        if code.startswith(q_upper):
            matches.append({
                "code": entry['iata'],
                "name": entry.get('name', ''),
                "city": entry.get('city', ''),
                "country": entry.get('country', ''),
                "timezone": entry['tz'],
                "latitude": entry['lat'],
                "longitude": entry['lon'],
            })
        if len(matches) >= 20:
            break

    return {"results": matches, "total": len(matches)}


# ============================================================================
# RUN SERVER
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    # Use Railway's PORT env var or default to 8000 for local dev
    port = int(os.environ.get("PORT", 8000))
    
    print("=" * 70)
    print("FATIGUE ANALYSIS API SERVER")
    print("=" * 70)
    print()
    print("Starting FastAPI server...")
    print(f"API will be available at: http://localhost:{port}")
    print(f"API docs at: http://localhost:{port}/docs")
    print()
    print("Frontend can now connect to:")
    print(f"  POST http://localhost:{port}/api/analyze")
    print(f"  POST http://localhost:{port}/api/visualize/chronogram")
    print(f"  GET  http://localhost:{port}/api/duty/{{analysis_id}}/{{duty_id}}")
    print()
    
    uvicorn.run(app, host="0.0.0.0", port=port, reload=True)
